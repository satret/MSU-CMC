# Домашняя работа по LLM: Fine-tuning с LoRA на задаче классификации эмоций (CEDR M7)

## Цель задания
Выполнить fine-tuning LLM с использованием **LoRA** (parameter-efficient fine-tuning): базовые веса модели «замораживаются», а обучаются добавленные низкоранговые матрицы-адаптеры, что резко снижает число обучаемых параметров. 

## Данные и постановка задачи
Использовалась та же задача, что и в ДЗ2: определение эмоции/настроения текста на датасете **Aniemore/cedr-m7**.  
Датасет: https://huggingface.co/datasets/Aniemore/cedr-m7. 

Постановка:
- Вход: текст на русском.
- Выход: одна метка класса (например, `neutral`, `sadness`, `happiness`, и т.д.), которую можно сравнить с эталоном.

## Базовая модель
В качестве инструктивной базы по смыслу задания должна использоваться instruction-tuned модель (пример в задании: Qwen2.5-3B-Instruct).
В данном выполнении применялась инструктивная модель, и обучение проводилось через LoRA-адаптеры.

## Разбиение на train/test и объём обучения
Данные были разделены на обучающую и тестовую части:
- **Train:** 1000 примеров.
- **Test:** 100 примеров.

Это "разумный" объём для быстрых прогонов, чтобы обучение не занимало слишком много времени.

## Протокол обучения (LoRA)
Обучение выполнялось с LoRA:
- Основные веса LLM заморожены.
- Обучались только LoRA-адаптеры, добавленные в выбранные слои (обычно attention-проекции), что соответствует идее PEFT.

## Сравнение качества: до и после fine-tuning
Метрика: accuracy/score по test-части (100 примеров), сравнение по одинаковому протоколу инференса.

Результаты:
- **До fine-tuning:** 37%
- **После fine-tuning (LoRA):** 51%

Улучшение: +14%. на тестовой выборке.

## Вывод
Fine-tuning с LoRA на CEDR M7 улучшил качество классификации эмоций на тестовых данных: модель стала лучше следовать задаче и выдавать правильные метки классов чаще, при этом без необходимости полного дообучения всех параметров.