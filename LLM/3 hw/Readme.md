# Домашняя работа по LLM: RAG по rus_xquadqa + Qdrant + LangChain

## Задание
Нужно было:
- Взять датасет: https://huggingface.co/datasets/bearberry/rus_xquadqa. 
- Объединить все сегменты датасета в один корпус (учесть повторы).  
- Поднять векторную БД **Qdrant** в режиме `:memory:` и проиндексировать корпус.
- Завернуть всё в **LangChain**, реализовать функцию поиска по БД. 
- На основе поиска + LLM реализовать **RAG** систему.  
- Вывести ответы на топ‑10 запросов из датасета **двумя моделями** и сравнить с эталоном.

## Датасет и корпус
**bearberry/rus_xquadqa** (в задании используется как набор вопросов/эталонных ответов).
Корпус формировался объединением всех сегментов в единый набор документов, при этом требовалось учитывать возможные дубликаты (повторы) при сборке.

## Индексация в Qdrant (:memory:)
Для быстрого эксперимента использовался локальный режим Qdrant с хранением только в памяти, который удобно включается параметром `location=":memory:"` при создании `QdrantVectorStore` в LangChain.
Этот режим подходит для тестов в ноутбуке: данные пропадают после завершения процесса/сессии.

## Эмбеддинги и поиск
Для векторизации документов и запросов использовались эмбеддинги **intfloat/multilingual-e5-large** с GPU. 
Функция поиска реализована через LangChain + Qdrant Vector Store, возвращая top‑k наиболее близких фрагментов корпуса по косинусной близости (семантический поиск через эмбеддинги).

## RAG-цепочка
RAG реализован как цепочка:
1) Вход: вопрос (query) из датасета.  
2) Retrieve: поиск релевантных фрагментов в Qdrant (top‑k). 
3) Generate: LLM получает вопрос + найденный контекст и генерирует финальный ответ.

## Модели для генерации
- Генеративная модель: **Mistral-7B-Instruct-v0.2** в 4-bit quantization.
- Сравнение проводилось между режимами:
  - **RAG** (с контекстом из Qdrant).
  - **No RAG** (генерация без внешнего контекста).

## Эксперимент и результаты (10 запросов)
Тестирование выполнено на **10** запросах из датасета (вопрос → ответ) с ручной проверкой соответствия эталону.

Ключевые наблюдения:
- Точность ответов:
  - **RAG**: 7/10 точных ответов.
  - **No RAG**: 2/10 точных ответов.
- Преимущества RAG:
  - Фактическая точность выше.
  - Больше конкретики (в т.ч. числа/факты), меньше «галлюцинаций».
- Проблемы:
  - Иногда модель добавляла лишний текст после основного ответа.

## Вывод
RAG-система заметно улучшила качество ответов за счёт добавления релевантного контекста из векторной БД: точность выросла с 20% до 70% на выбранных 10 примерах.
Практический эффект RAG в этом задании — снижение галлюцинаций и повышение фактологичности, так как генерация опирается на извлечённые документы, а не только на параметры модели.