# Домашняя работа по LLM: сравнение Zephyr-7B-Alpha и Mistral-7B-Instruct-v0.2

## Задание
Нужно было:  
- Запустить окружение (Google Colab / Kaggle / локально).  
- Создать ноутбук с загрузкой и использованием LLM по аналогии с примером из лекции.  
- Придумать 10 не самых простых вопросов (промптов) и сравнить 2 модели на выбор.  
- Сравнить ответы вручную по качеству: лучше model1, лучше model2, одинаковы.  
- Сдать: ноутбук + отчёт (PDF).

## Окружение
- Выполнено локально на GPU **RTX 3070 Ti**.

## Сравниваемые модели
- **Zephyr-7B-Alpha** — чат/инструктивно дообученная 7B-модель, ориентированная на диалоговые ответы и в целом англоязычное общение.
- **Mistral-7B-Instruct-v0.2** — instruct-тюненная версия Mistral 7B для следования инструкциям и генерации ответов на запросы.

## Критерии ручной оценки
Оценка выполнялась субъективно (human eval) по следующим признакам:
- Точность и фактологичность.
- Полнота и структура ответа.
- Соответствие языку запроса (RU/EN).
- Стабильность формата (без «мусора», повторов, обрывов).
- Полезность в контексте запроса (насколько ответ применим).

## Результаты по 10 промптам

### 1) «Квантовая механика»
- Zephyr-7B-Alpha: чёткое объяснение (EN).  
- Mistral-7B-Instruct-v0.2: объяснение (RU), но кратко.  
Вердикт: лучше **Zephyr**.

### 2) «Рассказ о космосе»
- Zephyr-7B-Alpha: развёрнутый sci‑fi стиль.  
- Mistral-7B-Instruct-v0.2: кратко (RU).  
Вердикт: лучше **Zephyr** (по богатству/деталям).

### 3) «Рецепт борща»
- Zephyr-7B-Alpha: корректный рецепт без артефактов.  
- Mistral-7B-Instruct-v0.2: поломанный текст, повторы, искажения (“бапчан”).  
Вердикт: лучше **Zephyr**.

### 4) «Блокчейн»
- Zephyr-7B-Alpha: хорошее объяснение (RU).  
- Mistral-7B-Instruct-v0.2: структурированное, но на EN.  
Вердикт: **одинаково** (разные плюсы: язык vs структура).

### 5) «Преступление и наказание»
- Zephyr-7B-Alpha: грубая фактическая ошибка (персонажи “вымышлены”).  
- Mistral-7B-Instruct-v0.2: артефакты (часть на китайском), искажения имён, обрыв.  
Вердикт: **одинаково** (обе не справились надёжно).

### 6) «Сборка на Axe в Dota 2»
- Zephyr-7B-Alpha: выдумал “Axes of Evil”.  
- Mistral-7B-Instruct-v0.2: перепутал с Counter‑Strike.  
Вердикт: **одинаково** (обе ошиблись по домену).

### 7) «Поздравление Артуру»
- Zephyr-7B-Alpha: развёрнуто, но шаблонно.  
- Mistral-7B-Instruct-v0.2: аналогично, чуть короче.  
Вердикт: **одинаково**.

### 8) «Градиентный спуск»
- Zephyr-7B-Alpha: чёткое объяснение (EN).  
- Mistral-7B-Instruct-v0.2: чёткое объяснение (EN).  
Вердикт: **одинаково**.

### 9) «Идеи стартапов»
- Zephyr-7B-Alpha: 10 идей, структурировано.  
- Mistral-7B-Instruct-v0.2: 7 идей (RU), ответ обрезан.  
Вердикт: лучше **Zephyr**.

### 10) «Шутка про программистов»
- Zephyr-7B-Alpha: классическая шутка про arrays.  
- Mistral-7B-Instruct-v0.2: та же шутка + ещё одна в начале.  
Вердикт: лучше **Mistral** (больше вариативности).

## Вывод
- **Zephyr-7B-Alpha** в этом тесте чаще давал развёрнутые и аккуратно оформленные ответы, но мог игнорировать язык запроса и допускал серьёзные фактологические ошибки на гуманитарных темах. 
- **Mistral-7B-Instruct-v0.2** чаще подхватывал русский язык и отвечал лаконичнее, но местами был менее стабильным (артефакты, обрывы) и хуже держал качество на «сложных» промптах в этом прогоне.